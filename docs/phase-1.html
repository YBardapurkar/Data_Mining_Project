<!DOCTYPE html>
<!--[if IE 8 ]><html class="no-js oldie ie8" lang="en"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>

	<!--- basic page needs
   	================================================== -->
	<meta charset="utf-8">
	<title>Data Mining Term Project Proposal (Fall 2019) - Yash Bardapurkar</title>
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- mobile specific metas
   	================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
 		================================================== -->
	<link rel="stylesheet" href="css/base.css">
	<link rel="stylesheet" href="css/main.css">
	<link rel="stylesheet" href="css/vendor.css">

	<!-- script
   	================================================== -->
	<!-- <script src="js/modernizr.js"></script> -->
	<!-- <script src="js/pace.min.js"></script> -->
	<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>


	<!-- favicons
   	================================================== -->
	<!-- <link rel="icon" type="image/png" href="favicon.png"> -->

</head>

<body>

	<section class="project">
		<h1>Data Mining Term Project (Fall 2019)</h1>

		<h1>Movie Search and Classifier</h1>

		<h2>Phase 1: Movie Search</h2>

		<a href="https://ybardapurkar.pythonanywhere.com/" target="_blank">Demo Link</a><br>
		<a href="https://github.com/YBardapurkar/Data_Mining_Project" target="_blank">GitHub Link</a><br>
		<br>

		<b>Dataset</b><br>
		The dataset contains metadata for 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017. Data points include cast, crew, plot keywords, budget, revenue, posters, release dates, languages, production companies, countries etc.
		<a href="https://www.kaggle.com/rounakbanik/the-movies-dataset" target="_blank">https://www.kaggle.com/rounakbanik/the-movies-dataset</a><br>
		<br>

		<b>Pre-processing</b><br>
		In the pre-processing step, for each document in the dataset, we create 
		<ul>
		<li>unique_tokens: this is the set of all the tokens in the all the documents.<br>
		<code>unique_tokens = {..., 'hanna', 'adventur', 'trap', 'syndic', 'scene', 'sibl', 'asid', 'glo', ...}</code></li>

		<li>document_frequency: this stores the count of documents a token in present in.<br>
		<code>document_frequency = {..., 'buzz': 1, 'differ': 1, 'onto': 1, 'woodi': 1, 'asid': 1, 'stori': 1, 'live': 2, ...}</code></li>

		<li>postings: this stores the list of documents a token is present in, along with the number of occurences in that document.<br>
		<code>postings = {..., 'hamm': {'198185': 1, '68139': 1}, 'pathway': {'159012': 1, '179340': 1, '376233': 1, '318832': 1, '440249': 1}, 'cultura': {'159012': 2}, ...}</code></li>

		<li>lengths: this stores the length of each document.<br>
		<code>lengths = {..., '805': 25, '34584': 34, '34636': 26, '2182': 34, '28070': 20, ...}</code></li>
		</ul>

		<b>Calculations</b><br>
		First, the query entered by the user is tokenized, and for each query token, the list of all the documents the token is present in is returned. Then, the document vector is created using the following formulae.<br>
		TF of a token in a document is calculated by the formula:<br>
		<code>tf = self.postings[query_term][movie_id] / self.lengths[movie_id]</code><br>
		
		IDF of a token is calculated by the formula:<br>
		<code>idf = log10(len(self.lengths) / self.document_frequency[query_term])</code><br>

		Documents are ranked by their score of cosine similarity based on the query tokens.<br>
		<code>dot(query_vector, document_vectors[movie_id]) / (norm(query_vector) * norm(document_vectors[movie_id]))</code><br>

		Finally, the documents are sorted by the decreasing order of the score, and top five results are returned.<br>
		<br>

		<b>Challenges Faced</b><br>
		The biggest challenge faced in the project was deploying the Flask app on PythonAnywhere. Because the pre-processing takes a very large amount of time, the deployment would always time-out. This was mitigated by using the Pickle library in python.<br>
		Pickle is a serialization and deserialization library, which can serialize or deserialize python variables to store them into files, or read them from files. The pre-processing step was carried out in the local machine and the resulting pickle data files were created, so that whenever
		the project was run, the pre-processing step could be skipped after the initial run, and the pre-processing data would simply read from the file. This decreased the app deployment time from several minutes to a few seconds, and also solved the time-out problem in PythonAnywhere.<br>
		<br>

		<b>References</b><br>
		<ul>
		<li><a href="https://www.stackoverflow.com">https://www.stackoverflow.com</a></li>
		<li><a href="https://www.youtube.com/watch?v=Flpj_D8b1Vg">https://www.youtube.com/watch?v=Flpj_D8b1Vg</a></li>
		<li><a href="https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/">https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/</a></li>
		<li><a href="https://github.com/BhaskarTrivedi/QuerySearch_Recommentation_Classification">https://github.com/BhaskarTrivedi/QuerySearch_Recommentation_Classification</a></li>
		<li><a href="https://docs.python.org/3.4/library/pickle.html">https://docs.python.org/3.4/library/pickle.html</a></li>
		</ul>

	</section>

	<!-- Java Script
   	================================================== -->
<!-- 	<script src="js/jquery-2.1.3.min.js"></script>
	<script src="js/plugins.js"></script>
	<script src="js/main.js"></script> -->
</body>

</html>